{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with `traffic_last_5min` feature\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we'll train a taxifare prediction model but this time with an additional feature of `traffic_last_5min`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, DenseFeatures\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print(tf.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT=qwiklabs-gcp-00-eeb852ce8ccb\n",
      "env: BUCKET=qwiklabs-gcp-00-eeb852ce8ccb\n",
      "env: REGION=us-central1\n"
     ]
    }
   ],
   "source": [
    "# Change below if necessary\n",
    "PROJECT = !gcloud config get-value project  # noqa: E999\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "%env PROJECT=$PROJECT\n",
    "%env BUCKET=$BUCKET\n",
    "%env REGION=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [ai/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set ai/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 2186310 Oct  4 18:39 ../data/taxi-traffic-test.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 9713118 Oct  4 18:39 ../data/taxi-traffic-train.csv\n",
      "-rw-r--r-- 1 jupyter jupyter 2036826 Oct  4 18:39 ../data/taxi-traffic-valid.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data/taxi-traffic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ../data/taxi-traffic-test.csv <==\n",
      "15.7,6,12,-73.990072,40.758199,-73.974686,40.742004,2089\n",
      "6.1,7,2,-73.95647,40.771226,-73.971845,40.750089,1738\n",
      "4.1,6,18,-73.987871,40.759855,-73.996375,40.763728,2971\n",
      "5.7,2,18,-73.974177,40.761154,-73.980953,40.769357,2320\n",
      "7.4,4,23,-73.924908,40.741879,-73.897524,40.747867,1491\n",
      "20.5,1,15,-73.957528,40.766847,-73.870813,40.774044,1794\n",
      "6.5,6,9,-73.996553,40.725558,-73.992503,40.737248,2341\n",
      "4.1,4,11,-73.98353,40.746821000000004,-73.976831,40.751082000000004,2329\n",
      "10.5,3,18,-73.863998,40.770439,-73.91671099999999,40.773011,2318\n",
      "10.1,6,1,-73.979685,40.727247999999996,-73.952508,40.772492,1455\n",
      "\n",
      "==> ../data/taxi-traffic-train.csv <==\n",
      "6.1,2,0,-73.98689499999999,40.729723,-74.00631,40.739407,1129\n",
      "9.7,7,0,-73.94578299999999,40.777807,-73.97539,40.757712,2876\n",
      "5.3,6,0,-74.00644,40.739349,-73.999379,40.731804,3950\n",
      "7.3,5,0,-73.96611800000001,40.753983000000005,-73.945605,40.782802000000004,1334\n",
      "6.5,7,0,-73.974153,40.762767,-73.989152,40.742727,2623\n",
      "22.9,1,0,-73.977188,40.774063,-73.962647,40.654768,2833\n",
      "22.9,2,0,-74.00188,40.745946999999994,-73.968497,40.639375,2002\n",
      "6.1,3,0,-73.994051,40.751077,-73.977333,40.778875,661\n",
      "5.3,5,0,-73.980898,40.744515,-73.973383,40.753496999999996,1938\n",
      "6.5,7,0,-74.00540600000001,40.708533,-74.005498,40.725617,2781\n",
      "\n",
      "==> ../data/taxi-traffic-valid.csv <==\n",
      "7.7,2,11,-73.97463,40.742118,-73.98544,40.760585999999996,1059\n",
      "30.1,7,1,-73.956921,40.777588,-73.965109,40.673271,2225\n",
      "7.7,6,13,-73.98073199999999,40.742109,-73.96415400000001,40.764891999999996,1994\n",
      "24.67,4,4,-73.953387,40.822733,-73.878697,40.755373,321\n",
      "7.7,2,1,-73.982304,40.723572,-73.972778,40.74928,1115\n",
      "8.1,5,18,-73.98474300000001,40.749171999999994,-74.00232,40.72825,2697\n",
      "6.1,4,1,-73.983588,40.72224,-73.997302,40.720786,868\n",
      "19.07,3,1,-73.94446500000001,40.807284,-73.876339,40.763073999999996,711\n",
      "12.5,4,10,-73.98696899999999,40.722343,-74.01621,40.715067,1990\n",
      "5.7,7,18,-74.007972,40.738759,-73.991973,40.73704,2048\n"
     ]
    }
   ],
   "source": [
    "!head ../data/taxi-traffic*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tf.data to read the CSV files\n",
    "\n",
    "These functions for reading data from the csv files are similar to what we used in the Introduction to Tensorflow module. Note that here we have an addtional feature `traffic_last_5min`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    \"fare_amount\",\n",
    "    \"dayofweek\",\n",
    "    \"hourofday\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"traffic_last_5min\",\n",
    "]\n",
    "LABEL_COLUMN = \"fare_amount\"\n",
    "DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
    "\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    features = row_data\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size=1, mode=tf.estimator.ModeKeys.EVAL):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        pattern, batch_size, CSV_COLUMNS, DEFAULTS\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(features_and_labels)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLS = [\n",
    "    \"dayofweek\",\n",
    "    \"hourofday\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"traffic_last_5min\",\n",
    "]\n",
    "\n",
    "# Create input layer of feature columns\n",
    "feature_columns = {\n",
    "    colname: tf.feature_column.numeric_column(colname)\n",
    "    for colname in INPUT_COLS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple keras DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "def build_model(dnn_hidden_units):\n",
    "    model = Sequential(DenseFeatures(feature_columns=feature_columns.values()))\n",
    "\n",
    "    for num_nodes in dnn_hidden_units:\n",
    "        model.add(Dense(units=num_nodes, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Create a custom evaluation metric\n",
    "    def rmse(y_true, y_pred):\n",
    "        return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "    # Compile the keras model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can call the `build_model` to create the model. Here we'll have two hidden layers before our final output layer. And we'll train with the same parameters we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:47:18.503616: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200205000 Hz\n",
      "2021-10-11 17:47:18.504352: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a6bb1f840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-11 17:47:18.504433: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-10-11 17:47:18.504824: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS = [32, 8]\n",
    "\n",
    "model = build_model(dnn_hidden_units=HIDDEN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 6  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 60  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 10000  # enough to get a reasonable sample\n",
    "\n",
    "trainds = create_dataset(\n",
    "    pattern=\"../data/taxi-traffic-train*\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode=tf.estimator.ModeKeys.TRAIN,\n",
    ")\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern=\"../data/taxi-traffic-valid*\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode=tf.estimator.ModeKeys.EVAL,\n",
    ").take(NUM_EVAL_EXAMPLES // 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('hourofday', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'ExpandDims_5:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'ExpandDims_6:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('hourofday', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'ExpandDims_5:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'ExpandDims_6:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:51:31.366316: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('hourofday', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'ExpandDims_5:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'ExpandDims_6:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('hourofday', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'ExpandDims_5:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'ExpandDims_6:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:51:42.396557: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 362 of 1000\n",
      "2021-10-11 17:51:52.399534: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 793 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 182795.1719 - rmse: 427.5455 - mse: 182795.1719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:51:57.550425: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('hourofday', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'ExpandDims_5:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'ExpandDims_6:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('hourofday', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'ExpandDims_5:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'ExpandDims_6:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 182795.1719 - rmse: 427.5455 - mse: 182795.1719 - val_loss: 127701.5312 - val_rmse: 357.2911 - val_mse: 127701.5312\n",
      "Epoch 2/60\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:51:59.423884: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 185756.5156 - rmse: 430.9948 - mse: 185756.5156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:51:59.730933: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59\n",
      "2021-10-11 17:51:59.732332: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.trace.json.gz\n",
      "2021-10-11 17:51:59.738304: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59\n",
      "2021-10-11 17:51:59.738582: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.memory_profile.json.gz\n",
      "2021-10-11 17:51:59.739187: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59Dumped tool data for xplane.pb to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./taxi_trained/train/plugins/profile/2021_10_11_17_51_59/asl.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 185756.5156 - rmse: 430.9948 - mse: 185756.5156 - val_loss: 111503.9141 - val_rmse: 333.8880 - val_mse: 111503.9141\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 2s 2s/step - loss: 112307.3750 - rmse: 335.1229 - mse: 112307.3750 - val_loss: 96502.5938 - val_rmse: 310.6206 - val_mse: 96502.5938\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70722.9453 - rmse: 265.9379 - mse: 70722.9453 - val_loss: 83986.0234 - val_rmse: 289.7795 - val_mse: 83986.0234\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 122573.6484 - rmse: 350.1052 - mse: 122573.6484 - val_loss: 71586.4922 - val_rmse: 267.5207 - val_mse: 71586.4922\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 74065.6484 - rmse: 272.1501 - mse: 74065.6484 - val_loss: 60578.9688 - val_rmse: 246.0974 - val_mse: 60578.9688\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 58750.9766 - rmse: 242.3860 - mse: 58750.9766 - val_loss: 50858.2930 - val_rmse: 225.4890 - val_mse: 50858.2930\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 60242.1680 - rmse: 245.4428 - mse: 60242.1680 - val_loss: 42334.1523 - val_rmse: 205.7350 - val_mse: 42334.1523\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 60105.5273 - rmse: 245.1643 - mse: 60105.5273 - val_loss: 34148.7812 - val_rmse: 184.7524 - val_mse: 34148.7812\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 56193.3438 - rmse: 237.0513 - mse: 56193.3438 - val_loss: 27455.1230 - val_rmse: 165.6682 - val_mse: 27455.1230\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 28704.4961 - rmse: 169.4240 - mse: 28704.4961 - val_loss: 22714.5469 - val_rmse: 150.6921 - val_mse: 22714.5469\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 39336.8945 - rmse: 198.3353 - mse: 39336.8945 - val_loss: 18430.4609 - val_rmse: 135.7367 - val_mse: 18430.4609\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 29122.8438 - rmse: 170.6542 - mse: 29122.8438 - val_loss: 14735.7852 - val_rmse: 121.3749 - val_mse: 14735.7852\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 15227.9570 - rmse: 123.4016 - mse: 15227.9570 - val_loss: 11608.3691 - val_rmse: 107.7148 - val_mse: 11608.3691\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6680.8130 - rmse: 81.7362 - mse: 6680.8130 - val_loss: 8989.0762 - val_rmse: 94.7964 - val_mse: 8989.0762\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8478.5498 - rmse: 92.0790 - mse: 8478.5498 - val_loss: 6834.8345 - val_rmse: 82.6611 - val_mse: 6834.8345\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11614.3096 - rmse: 107.7697 - mse: 11614.3096 - val_loss: 4992.8442 - val_rmse: 70.6488 - val_mse: 4992.8442\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4873.0381 - rmse: 69.8072 - mse: 4873.0381 - val_loss: 3471.5532 - val_rmse: 58.9083 - val_mse: 3471.5532\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5806.9531 - rmse: 76.2034 - mse: 5806.9531 - val_loss: 2314.4438 - val_rmse: 48.1000 - val_mse: 2314.4438\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2353.5820 - rmse: 48.5137 - mse: 2353.5820 - val_loss: 1465.6512 - val_rmse: 38.2774 - val_mse: 1465.6512\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1616.8578 - rmse: 40.2102 - mse: 1616.8578 - val_loss: 838.9298 - val_rmse: 28.9577 - val_mse: 838.9298\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 811.1196 - rmse: 28.4802 - mse: 811.1196 - val_loss: 447.9962 - val_rmse: 21.1593 - val_mse: 447.9962\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 395.8287 - rmse: 19.8954 - mse: 395.8287 - val_loss: 236.7807 - val_rmse: 15.3809 - val_mse: 236.7807\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 183.0764 - rmse: 13.5306 - mse: 183.0764 - val_loss: 170.2748 - val_rmse: 13.0351 - val_mse: 170.2748\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 129.2523 - rmse: 11.3689 - mse: 129.2523 - val_loss: 205.3821 - val_rmse: 14.3216 - val_mse: 205.3821\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 201.8162 - rmse: 14.2062 - mse: 201.8162 - val_loss: 329.5942 - val_rmse: 18.1476 - val_mse: 329.5942\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 300.2361 - rmse: 17.3273 - mse: 300.2361 - val_loss: 517.5001 - val_rmse: 22.7466 - val_mse: 517.5001\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 448.7128 - rmse: 21.1828 - mse: 448.7128 - val_loss: 736.4244 - val_rmse: 27.1340 - val_mse: 736.4244\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 576.7869 - rmse: 24.0164 - mse: 576.7869 - val_loss: 975.6583 - val_rmse: 31.2340 - val_mse: 975.6583\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 711.9475 - rmse: 26.6823 - mse: 711.9475 - val_loss: 1199.5948 - val_rmse: 34.6324 - val_mse: 1199.5948\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1106.2113 - rmse: 33.2598 - mse: 1106.2113 - val_loss: 1429.8199 - val_rmse: 37.8102 - val_mse: 1429.8199\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1700.9905 - rmse: 41.2431 - mse: 1700.9905 - val_loss: 1621.9302 - val_rmse: 40.2720 - val_mse: 1621.9302\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1546.3817 - rmse: 39.3241 - mse: 1546.3817 - val_loss: 1766.4344 - val_rmse: 42.0278 - val_mse: 1766.4344\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 1497.6074 - rmse: 38.6989 - mse: 1497.6074 - val_loss: 1886.1882 - val_rmse: 43.4278 - val_mse: 1886.1882\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 1428.3123 - rmse: 37.7930 - mse: 1428.3123 - val_loss: 1968.6429 - val_rmse: 44.3676 - val_mse: 1968.6429\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 2505.3091 - rmse: 50.0531 - mse: 2505.3091 - val_loss: 2018.6945 - val_rmse: 44.9260 - val_mse: 2018.6945\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2129.7539 - rmse: 46.1493 - mse: 2129.7539 - val_loss: 2006.7928 - val_rmse: 44.7931 - val_mse: 2006.7928\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 2643.8059 - rmse: 51.4180 - mse: 2643.8059 - val_loss: 1961.3632 - val_rmse: 44.2851 - val_mse: 1961.3632\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1905.3335 - rmse: 43.6501 - mse: 1905.3335 - val_loss: 1873.7072 - val_rmse: 43.2827 - val_mse: 1873.7072\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2029.8022 - rmse: 45.0533 - mse: 2029.8022 - val_loss: 1758.0063 - val_rmse: 41.9270 - val_mse: 1758.0063\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1763.3153 - rmse: 41.9918 - mse: 1763.3153 - val_loss: 1641.3190 - val_rmse: 40.5112 - val_mse: 1641.3190\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 1881.1632 - rmse: 43.3724 - mse: 1881.1632 - val_loss: 1498.8541 - val_rmse: 38.7123 - val_mse: 1498.8541\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1152.0743 - rmse: 33.9422 - mse: 1152.0743 - val_loss: 1360.7087 - val_rmse: 36.8864 - val_mse: 1360.7087\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1198.7938 - rmse: 34.6236 - mse: 1198.7938 - val_loss: 1211.2653 - val_rmse: 34.8013 - val_mse: 1211.2653\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1492.6530 - rmse: 38.6349 - mse: 1492.6530 - val_loss: 1058.0884 - val_rmse: 32.5227 - val_mse: 1058.0884\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 1229.1407 - rmse: 35.0591 - mse: 1229.1407 - val_loss: 908.4136 - val_rmse: 30.1360 - val_mse: 908.4136\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 852.5544 - rmse: 29.1985 - mse: 852.5544 - val_loss: 775.6108 - val_rmse: 27.8466 - val_mse: 775.6108\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 828.8291 - rmse: 28.7894 - mse: 828.8291 - val_loss: 645.0176 - val_rmse: 25.3930 - val_mse: 645.0176\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 712.8680 - rmse: 26.6996 - mse: 712.8680 - val_loss: 544.1351 - val_rmse: 23.3181 - val_mse: 544.1351\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 365.5890 - rmse: 19.1204 - mse: 365.5890 - val_loss: 442.4311 - val_rmse: 21.0240 - val_mse: 442.4311\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 444.3436 - rmse: 21.0795 - mse: 444.3436 - val_loss: 360.0707 - val_rmse: 18.9653 - val_mse: 360.0707\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - 2s 2s/step - loss: 328.0283 - rmse: 18.1116 - mse: 328.0283 - val_loss: 298.0123 - val_rmse: 17.2579 - val_mse: 298.0123\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 207.7389 - rmse: 14.4131 - mse: 207.7389 - val_loss: 244.7331 - val_rmse: 15.6264 - val_mse: 244.7331\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 197.5155 - rmse: 14.0540 - mse: 197.5155 - val_loss: 210.3017 - val_rmse: 14.4956 - val_mse: 210.3017\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 119.8655 - rmse: 10.9483 - mse: 119.8655 - val_loss: 178.5757 - val_rmse: 13.3445 - val_mse: 178.5757\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 207.9326 - rmse: 14.4199 - mse: 207.9326 - val_loss: 165.8022 - val_rmse: 12.8618 - val_mse: 165.8022\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 113.6646 - rmse: 10.6614 - mse: 113.6646 - val_loss: 151.9939 - val_rmse: 12.3222 - val_mse: 151.9939\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 185.5261 - rmse: 13.6208 - mse: 185.5261 - val_loss: 154.1387 - val_rmse: 12.4006 - val_mse: 154.1387\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - 1s 1s/step - loss: 133.9850 - rmse: 11.5752 - mse: 133.9850 - val_loss: 160.5724 - val_rmse: 12.6598 - val_mse: 160.5724\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 113.4558 - rmse: 10.6516 - mse: 113.4558 - val_loss: 157.5322 - val_rmse: 12.5478 - val_mse: 157.5322\n",
      "CPU times: user 2min 22s, sys: 1min 34s, total: 3min 56s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "LOGDIR = \"./taxi_trained\"\n",
    "history = model.fit(\n",
    "    x=trainds,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=NUM_EVALS,\n",
    "    validation_data=evalds,\n",
    "    callbacks=[TensorBoard(LOGDIR)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_COLS = [\"rmse\", \"val_rmse\"]\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'dayofweek': <tf.Tensor 'ExpandDims:0' shape=(1, 1) dtype=int32>, 'hourofday': <tf.Tensor 'ExpandDims_3:0' shape=(1, 1) dtype=int32>, 'pickup_longitude': <tf.Tensor 'ExpandDims_5:0' shape=(1, 1) dtype=float32>, 'pickup_latitude': <tf.Tensor 'ExpandDims_4:0' shape=(1, 1) dtype=float32>, 'dropoff_longitude': <tf.Tensor 'ExpandDims_2:0' shape=(1, 1) dtype=float32>, 'dropoff_latitude': <tf.Tensor 'ExpandDims_1:0' shape=(1, 1) dtype=float32>, 'traffic_last_5min': <tf.Tensor 'ExpandDims_6:0' shape=(1, 1) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'dayofweek': <tf.Tensor 'ExpandDims:0' shape=(1, 1) dtype=int32>, 'hourofday': <tf.Tensor 'ExpandDims_3:0' shape=(1, 1) dtype=int32>, 'pickup_longitude': <tf.Tensor 'ExpandDims_5:0' shape=(1, 1) dtype=float32>, 'pickup_latitude': <tf.Tensor 'ExpandDims_4:0' shape=(1, 1) dtype=float32>, 'dropoff_longitude': <tf.Tensor 'ExpandDims_2:0' shape=(1, 1) dtype=float32>, 'dropoff_latitude': <tf.Tensor 'ExpandDims_1:0' shape=(1, 1) dtype=float32>, 'traffic_last_5min': <tf.Tensor 'ExpandDims_6:0' shape=(1, 1) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-7.959366]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    x={\n",
    "        \"dayofweek\": tf.convert_to_tensor([6]),\n",
    "        \"hourofday\": tf.convert_to_tensor([17]),\n",
    "        \"pickup_longitude\": tf.convert_to_tensor([-73.982683]),\n",
    "        \"pickup_latitude\": tf.convert_to_tensor([40.742104]),\n",
    "        \"dropoff_longitude\": tf.convert_to_tensor([-73.983766]),\n",
    "        \"dropoff_latitude\": tf.convert_to_tensor([40.755174]),\n",
    "        \"traffic_last_5min\": tf.convert_to_tensor([114]),\n",
    "    },\n",
    "    steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs_5:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs_6:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 17:56:31.330223: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs/dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs/hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs/traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs/dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs/hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs/traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs/dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs/hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs/traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('dayofweek', <tf.Tensor 'inputs/dayofweek:0' shape=(None, 1) dtype=float32>), ('hourofday', <tf.Tensor 'inputs/hourofday:0' shape=(None, 1) dtype=float32>), ('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('traffic_last_5min', <tf.Tensor 'inputs/traffic_last_5min:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Assets written to: ./export/savedmodel/20211011175630/assets\n",
      "INFO:tensorflow:Assets written to: ./export/savedmodel/20211011175630/assets\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"./export/savedmodel\"\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "EXPORT_PATH = os.path.join(OUTPUT_DIR, datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "model.save(EXPORT_PATH)  # with default serving function\n",
    "os.environ[\"EXPORT_PATH\"] = EXPORT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the last `gcloud` call below, which deploys the mode, can take a few minutes, and you might not see the earlier `echo` outputs while that job is still running. If you want to make sure that your notebook is not stalled and your model is actually getting deployed, view your models in the console at https://console.cloud.google.com/vertex-ai/models, click on your model, and you should see your endpoint listed with an \"in progress\" icon next to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-00-eeb852ce8ccb/taxifare_20211011_175855/\n",
      "MODEL_DISPLAYNAME=taxifare_20211011_175855\n",
      "MODEL_RESOURCENAME=projects/432069008306/locations/us-central1/models/8415248582625460224\n",
      "MODEL_ID=8415248582625460224\n",
      "ENDPOINT_DISPLAYNAME=taxifare_endpoint_20211011_175855\n",
      "ENDPOINT_RESOURCENAME=projects/432069008306/locations/us-central1/endpoints/5048517590096281600\n",
      "ENDPOINT_ID=5048517590096281600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://./export/savedmodel/20211011175630/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/savedmodel/20211011175630/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/savedmodel/20211011175630/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "- [3 files][241.6 KiB/241.6 KiB]                                                \n",
      "Operation completed over 3 objects/241.6 KiB.                                    \n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [4138737826248261632]...\n",
      ".......................done.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [6248674251671339008]...\n",
      ".......................done.\n",
      "Created Vertex AI endpoint: projects/432069008306/locations/us-central1/endpoints/5048517590096281600.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [6777847207887372288]...\n",
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Deployed a model to the endpoint 5048517590096281600. Id of the deployed model: 4559551575084761088.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "MODEL_DISPLAYNAME=taxifare_$TIMESTAMP\n",
    "ENDPOINT_DISPLAYNAME=taxifare_endpoint_$TIMESTAMP\n",
    "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\"\n",
    "ARTIFACT_DIRECTORY=gs://${BUCKET}/${MODEL_DISPLAYNAME}/\n",
    "echo $ARTIFACT_DIRECTORY\n",
    "\n",
    "gsutil cp -r ${EXPORT_PATH}/* ${ARTIFACT_DIRECTORY}\n",
    "\n",
    "# Model\n",
    "MODEL_RESOURCENAME=$(gcloud ai models upload \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$MODEL_DISPLAYNAME \\\n",
    "    --container-image-uri=$IMAGE_URI \\\n",
    "    --artifact-uri=$ARTIFACT_DIRECTORY \\\n",
    "    --format=\"value(model)\")\n",
    "\n",
    "MODEL_ID=$(echo $MODEL_RESOURCENAME | cut -d\"/\" -f6)\n",
    "\n",
    "echo \"MODEL_DISPLAYNAME=${MODEL_DISPLAYNAME}\"\n",
    "echo \"MODEL_RESOURCENAME=${MODEL_RESOURCENAME}\"\n",
    "echo \"MODEL_ID=${MODEL_ID}\"\n",
    "\n",
    "# Endpoint\n",
    "ENDPOINT_RESOURCENAME=$(gcloud ai endpoints create \\\n",
    "  --region=$REGION \\\n",
    "  --display-name=$ENDPOINT_DISPLAYNAME \\\n",
    "  --format=\"value(name)\")\n",
    "\n",
    "ENDPOINT_ID=$(echo $ENDPOINT_RESOURCENAME | cut -d\"/\" -f6)\n",
    "\n",
    "echo \"ENDPOINT_DISPLAYNAME=${ENDPOINT_DISPLAYNAME}\"\n",
    "echo \"ENDPOINT_RESOURCENAME=${ENDPOINT_RESOURCENAME}\"\n",
    "echo \"ENDPOINT_ID=${ENDPOINT_ID}\"\n",
    "\n",
    "# Deployment\n",
    "DEPLOYEDMODEL_DISPLAYNAME=${MODEL_DISPLAYNAME}_deployment\n",
    "MACHINE_TYPE=n1-standard-2\n",
    "MIN_REPLICA_COUNT=1\n",
    "MAX_REPLICA_COUNT=3\n",
    "\n",
    "gcloud ai endpoints deploy-model $ENDPOINT_RESOURCENAME \\\n",
    "  --region=$REGION \\\n",
    "  --model=$MODEL_RESOURCENAME \\\n",
    "  --display-name=$DEPLOYEDMODEL_DISPLAYNAME \\\n",
    "  --machine-type=$MACHINE_TYPE \\\n",
    "  --min-replica-count=$MIN_REPLICA_COUNT \\\n",
    "  --max-replica-count=$MAX_REPLICA_COUNT \\\n",
    "  --traffic-split=0=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the `ENDPOINT_RESOURCENAME` printed above, as you will need it in the next lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model deployment can be initiated from the Vertex AI Python SDK as well, as seen below. In this case, we do not need to create the Endpoint ourselves (we could though), but it is implicitly created during the `model.deploy()` call."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TIMESTAMP = datetime.strftime(datetime.now(), \"%Y%m%d_%H%M%S\")\n",
    "MODEL_DISPLAYNAME = f\"taxifare_{TIMESTAMP}\"\n",
    "ENDPOINT_NAME = f\"taxifare_endpoint_{TIMESTAMP}\"\n",
    "ARTIFACT_DIRECTORY = f\"gs://{BUCKET}/{MODEL_DISPLAYNAME}/\"\n",
    "print(ARTIFACT_DIRECTORY)\n",
    "IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\"\n",
    "\n",
    "!gsutil cp -r $EXPORT_PATH/* $ARTIFACT_DIRECTORY\n",
    "\n",
    "aiplatform.init(project=PROJECT, location=REGION)\n",
    "\n",
    "# Model\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAYNAME,\n",
    "    artifact_uri=ARTIFACT_DIRECTORY,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)\n",
    "\n",
    "# Deployment\n",
    "DEPLOYED_MODEL_NAME = f\"{MODEL_DISPLAYNAME}_deployment\"\n",
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "MIN_REPLICA_COUNT = 1\n",
    "MAX_REPLICA_COUNT = 3\n",
    "\n",
    "model = aiplatform.Model(model_name=model.resource_name)\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=DEPLOYED_MODEL_NAME,\n",
    "    traffic_split={\"0\": 100},\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    min_replica_count=MIN_REPLICA_COUNT,\n",
    "    max_replica_count=MAX_REPLICA_COUNT,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(endpoint.display_name)\n",
    "print(endpoint.resource_name)\n",
    "print(f\"Model {model.display_name} deployed to Endpoint {endpoint.display_name}.\")\n",
    "print(f\"ENDPOINT_ID={endpoint.resource_name.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
